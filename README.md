# Large Language Models in Financial Decision-Making

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![Research](https://img.shields.io/badge/Type-Research_Framework-purple.svg)](#research-questions)

**An empirical framework for evaluating AI agents in financial markets**

This research framework provides rigorous methodological tools to assess Large Language Model performance against established quantitative trading strategies. The framework enables systematic investigation of memory adaptation, probabilistic calibration, and behavioral patterns in AI-driven financial decision-making.

---

## ğŸ¯ What This Does

### The Trading Process
Each day, the LLM analyzes market data and **chooses one action**:
- **BUY**: Take a long position (+1.0) - profit if market goes up
- **HOLD**: Stay in cash (0.0) - no profit/loss regardless of market movement
- **SELL**: Take a short position (-1.0) - profit if market goes down

The LLM receives technical indicators, can maintain a strategic journal, and may express emotional states. Performance is rigorously compared against traditional quantitative strategies.

### How It Works
The framework follows a systematic 5-step process:

1. **ğŸ“Š Data Preparation**: Load historical market data and compute comprehensive technical indicators (RSI, MACD, Stochastic Oscillator, Bollinger Bands, moving averages, volatility, momentum)
2. **ğŸ“ Prompt Engineering**: Build hierarchical prompts with 4 layers of memory:
   - **System Prompt**: Fixed rules and technical indicator definitions
   - **Raw Market Data**: Current conditions and 20-day technical history
   - **Strategic Journal**: LLM's recent 10 trading decisions with explanations
   - **Memory Blocks**: Weekly/monthly summaries generated by LLM analysis
   - **Performance Summary**: Real-time metrics vs S&P 500 benchmark
3. **ğŸ¤– LLM Decision Making**: Query language models via OpenRouter API to generate BUY/HOLD/SELL decisions with confidence scores and explanations
4. **ğŸ“ˆ Backtesting Engine**: Simulate trading performance over historical periods, tracking returns, risk metrics, and position management
5. **ğŸ“‹ Analysis & Reporting**: Generate comprehensive reports with statistical validation, behavioral pattern analysis, and performance comparisons

### Technical Indicator Memory System**
**Comprehensive technical analysis with historical context and aggregated insights**

The framework implements a dual-layer technical indicator system for maximum analytical depth:

- **ğŸ“ˆ Daily Historical Series**: 20-day lagged technical indicator values (RSI, MACD histogram, Stochastic %K, Bollinger Band position) in daily prompts for detailed pattern analysis
- **ğŸ“Š Aggregated Memory Context**: Weekly/monthly/quarterly/yearly memory includes aggregated technical statistics (averages, percentages, ranges) for efficient token usage
- **ğŸ¯ Current Day Analysis**: Real-time RSI, MACD, Stochastic Oscillator, and Bollinger Bands for immediate decision-making
- **ğŸ§  Multi-Timeframe Correlation**: LLMs can analyze technical signals across daily trends, weekly averages, and monthly patterns for sophisticated decision-making

### Recent Architectural Improvements ğŸš€

#### **Phase 3: Trading Engine Decomposition (COMPLETED)**
- **PerformanceTracker**: Extracted performance tracking logic into dedicated class
- **JournalManager**: Isolated strategic journal management with rolling window
- **TradeHistoryManager**: Centralized trading history CSV formatting
- **Impact**: Reduced `run_single_model` complexity by 29% (722â†’513 lines)

#### **Phase 4: Data Pipeline Optimization (COMPLETED)**
- **DataFrame Fragmentation Fix**: Eliminated 54 performance warnings
- **Batch Operations**: Replaced individual column assignments with `pd.concat()`
- **Performance**: Improved DataFrame memory efficiency
- **Impact**: 98% reduction in fragmentation warnings, faster test execution

#### **Memory System Architecture:**
```
LLM Prompt Structure:
â”œâ”€â”€ System Prompt (static rules)
â””â”€â”€ User Message (dynamic context)
    â”œâ”€â”€ Raw Technical Data
    â”œâ”€â”€ Strategic Journal (JournalManager) ğŸ§ 
    â”œâ”€â”€ Performance Summary (PerformanceTracker) ğŸ“ˆ
    â”œâ”€â”€ Memory Blocks (MemoryManager) ğŸ—ï¸
    â””â”€â”€ Trading History (TradeHistoryManager) ğŸ“‹
```

### Research Capabilities
- **ğŸ§ª Compare LLMs vs Traditional Strategies**: Test any LLM against momentum, mean-reversion, volatility timing, and other proven approaches
- **ğŸ§  Hierarchical Memory & Adaptation**: Study how LLMs learn from experience with multi-level memory system (daily, weekly, monthly, quarterly, yearly), strategic journals, feeling logs, and optional complete trading history
- **ğŸ¯ Calibration Analysis**: Assess if LLM confidence matches actual performance
- **ğŸ§® Behavioral Biases**: Detect human-like trading biases in AI decisions
- **ğŸ“Š Statistical Rigor**: Bootstrap testing, out-of-sample validation, risk-based HOLD evaluation

---

## ğŸ”¬ Research Objectives

### Memory and Learning Dynamics
**Investigation of temporal learning in sequential financial decisions**
- Analysis of hierarchical memory systems (daily, weekly, monthly, quarterly, yearly summaries)
- Assessment of multi-scale temporal learning and adaptation patterns
- Analysis of historical context integration in LLM decision processes
- Evaluation of adaptive behavior based on performance feedback
- Evaluation of emotional state impacts on decision quality

### Probabilistic Calibration
**Assessment of confidence-outcome alignment in AI predictions**
- Measurement of overconfidence/underconfidence patterns
- Decision-specific calibration analysis (BUY/SELL/HOLD)
- Longitudinal calibration stability assessment

### Behavioral Pattern Analysis
**Detection of systematic biases in AI trading behavior**
- Loss aversion quantification in position management
- Disposition effect identification in profit-taking behavior
- Risk management appropriateness in uncertain conditions

---

## ğŸ“Š At a Glance

| Component | Status | Description |
|-----------|--------|-------------|
| **LLM Integration** | âœ… OpenRouter API | BERT, GPT, Claude, Gemini models |
| **Memory System** | âœ… **4-Layer Hierarchical** | Journal + Periods + Performance + History |
| **Data Pipeline** | âœ… **Optimized** | Zero fragmentation warnings, batch operations |
| **Modular Architecture** | âœ… **29% Reduction** | Trading engine complexity reduced |
| **Baseline Strategies** | âœ… 7 Strategies | Momentum, Mean Reversion, Volatility Timing |
| **Statistical Validation** | âœ… Bootstrap Testing | Out-of-sample, significance testing |
| **Decision Analysis** | âœ… Dual-Criteria | Calibration + behavioral pattern analysis |
| **Reporting** | âœ… Comprehensive | Automated research reports |

---

## ğŸš€ Getting Started

### Modern Installation (Recommended)
```bash
# Install everything (core + development tools)
pip install -e .[dev]

# Or install core dependencies only
pip install -e .
```

### Quick Test Run
```bash
# Run with dummy model (no API key needed)
python -m src.main
```

### Development Workflow
```bash
# Run quality checks (linting, testing, type checking)
python scripts/dev-workflow.py check

# Windows users can also use:
dev check

# Linux/Mac users can also use:
make check
```

### Real LLM Experiment
```bash
# 1. Get OpenRouter API key from https://openrouter.ai/
#    See documentation: https://openrouter.ai/docs
export OPENROUTER_API_KEY="your_key_here"

# 2. Configure your experiment in src/config.py
TEST_MODE = False  # Set to False for full dataset (default: ~2700 days)
# Or customize: DAYS_TO_RUN = 100  # If keeping TEST_MODE = True

# 3. Choose LLM model
ACTIVE_MODEL = "bert"  # or other models

# 4. Run experiment
python -m src.main
```

### Traditional Installation (Alternative)
```bash
# Core dependencies
pip install pandas numpy scipy matplotlib requests

# Development dependencies (optional)
pip install pytest black flake8 mypy isort
```

## ğŸ› ï¸ Development Tools

### Cross-Platform Commands
```bash
# Quality assurance
python scripts/dev-workflow.py check    # Full check suite
python scripts/dev-workflow.py test     # Run tests only
python scripts/dev-workflow.py lint     # Code style checks

# Version management
python scripts/version.py get           # Current version
python scripts/version.py bump patch    # Bump patch version
python scripts/version.py tag           # Create git tag

# Collaboration helpers
python scripts/collaborate.py status    # Repository status
python scripts/collaborate.py branch    # Create feature branch
python scripts/collaborate.py pr        # Prepare for PR
```

### Windows Development
```batch
dev setup     # Install all dependencies
dev check     # Run quality checks
dev test      # Run tests
dev lint      # Check code style
dev clean     # Clean build artifacts
dev collab    # Collaboration tools
```

### Linux/Mac Development
```bash
make setup    # Install all dependencies
make check    # Run quality checks
make test     # Run tests
make lint     # Check code style
make clean    # Clean build artifacts
```

### Automated Quality Assurance
Every commit is automatically checked by our CI/CD pipeline:
- âœ… **Code Linting**: flake8, black, isort
- âœ… **Type Checking**: mypy validation
- âœ… **Testing**: pytest with coverage reporting (140+ tests)
- âœ… **Import Validation**: All dependencies properly declared
- âœ… **Memory System**: Comprehensive testing of 4-layer architecture
- âœ… **Data Pipeline**: Zero fragmentation warnings verified

**âš ï¸ Important**: Set `TEST_MODE = False` in `src/config.py` for meaningful results, or adjust `DAYS_TO_RUN` if keeping test mode.

## ğŸ“Š Sample Results (Dummy Model)

*These are comprehensive test results from a 1000-day simulation using a dummy model - run with real LLMs for actual research!*

### Strategy Performance Comparison
![Baseline Comparison](example_results/plots/dummy_model_memory_feeling_baseline_comparison.png)
*LLM strategies vs traditional approaches (dummy data for illustration)*

### Decision Calibration Analysis
![Calibration by Decision](example_results/plots/dummy_model_memory_feeling_calibration_by_decision.png)
*Confidence vs actual performance across BUY/HOLD/SELL decisions*

### Behavioral Pattern Analysis
![Decision Patterns](example_results/plots/dummy_model_memory_feeling_decision_patterns.png)
*Decision changes after wins vs losses - evidence of learning/adaptation*

### Risk Analysis
![Risk Analysis](example_results/plots/dummy_model_memory_feeling_risk_analysis.png)
*Comprehensive risk metrics including VaR, drawdowns, and stress testing*

### Rolling Performance
![Rolling Performance](example_results/plots/dummy_model_memory_feeling_rolling_performance.png)
*Rolling Sharpe ratio and performance metrics over different time windows*

### Technical Indicators Timeline
![Technical Indicators Timeline](example_results/plots/dummy_model_memory_feeling_technical_timeline.png)
*Evolution of RSI, MACD, Stochastic, and Bollinger Bands with trading decision overlays*

## ğŸ“ˆ Data Source

**Data Sources**: The framework works with publicly available financial market data in standard CSV format.

**Getting Data**:
- **Yahoo Finance**: Use `yfinance` library (recommended for research)
- **Alpha Vantage**: Free API with clear academic usage terms
- **Any CSV**: With columns: Date, Open, High, Low, Close, Volume

**Note**: Raw data files are not included in this repository. Users must obtain their own data sources for research and reproducibility.

---

---

## ğŸ—ï¸ Architecture

### **Hierarchical Memory System** ğŸ§ 
The framework implements a sophisticated 4-layer memory architecture enabling LLMs to maintain context across multiple timeframes:

#### **Memory Layers:**
1. **ğŸ§  Immediate Journal** (`JournalManager`): Last 10 trades with LLM's own explanations
2. **ğŸ“Š Period Summaries** (`MemoryManager`): Weekly/Monthly LLM-generated strategic analyses
3. **ğŸ“ˆ Performance Tracking** (`PerformanceTracker`): Real-time metrics vs benchmarks
4. **ğŸ“‹ Trading History** (`TradeHistoryManager`): Complete chronological record

#### **Key Benefits:**
- **Self-Reflection**: LLMs read their own past reasoning and adapt
- **Multi-Timeframe Learning**: Daily, weekly, monthly, and yearly insights
- **Context Preservation**: Complete trading history for pattern recognition
- **Behavioral Continuity**: Consistent decision-making across time

### **File Structure:**

```
ğŸ“ Root Level
â”œâ”€â”€ ğŸ“– README.md               # Main project documentation
â”œâ”€â”€ ğŸ“¦ pyproject.toml          # Modern Python packaging & metadata
â”œâ”€â”€ ğŸ“‹ requirements.txt       # Core dependency list
â”œâ”€â”€ ğŸ§ Makefile               # Unix/Linux development commands
â”œâ”€â”€ ğŸªŸ dev.bat                 # Windows development commands
â”œâ”€â”€ âš–ï¸ LICENSE                 # Project license
â”œâ”€â”€ ğŸ“ CHANGELOG.md           # Version history & changes
â””â”€â”€ ğŸ¤ CODE_OF_CONDUCT.md     # Community standards

ğŸ“ src/ (Core Architecture)
â”œâ”€â”€ ğŸ¯ main.py                 # Pipeline orchestrator
â”œâ”€â”€ ğŸ¤– openrouter_model.py     # LLM API integration
â”œâ”€â”€ ğŸ“Š backtest.py            # Strategy evaluation engine
â”œâ”€â”€ ğŸ§® baselines.py           # 7 traditional quantitative strategies
â”œâ”€â”€ ğŸ“ˆ statistical_validation.py # Bootstrap testing + out-of-sample
â”œâ”€â”€ ğŸ“‹ report_generator.py    # Automated research reports
â”œâ”€â”€ ğŸ“Š reporting.py           # Plotting & visualization
â”œâ”€â”€ âš™ï¸ config.py              # Experimental configurations
â”œâ”€â”€ ğŸ”§ data_prep.py           # Data preprocessing (optimized)
â”œâ”€â”€ ğŸ¯ decision_analysis.py   # Decision pattern analysis
â”œâ”€â”€ ğŸ¤– dummy_model.py         # Mock model for testing
â”œâ”€â”€ ğŸ“‹ prompts.py             # LLM prompt templates
â”œâ”€â”€ ğŸ¤– trading_engine.py      # Main experiment orchestration

ğŸ“ src/ (Memory System Components)
â”œâ”€â”€ ğŸ§  journal_manager.py     # Strategic journal management
â”œâ”€â”€ ğŸ“Š memory_manager.py      # Period-based memory storage
â”œâ”€â”€ ğŸ“ˆ performance_tracker.py # Real-time performance metrics
â”œâ”€â”€ ğŸ“‹ trade_history_manager.py # Trading history CSV formatting
â”œâ”€â”€ ğŸ—ï¸ memory_classes.py      # Memory data structures
â”œâ”€â”€ ğŸ“‹ prompt_builder.py      # Prompt construction utilities

ğŸ“ src/ (Configuration System)
â”œâ”€â”€ âš™ï¸ config_classes.py      # Type-safe configuration classes
â”œâ”€â”€ ğŸ”§ configuration_manager.py # Centralized configuration management
â”œâ”€â”€ ğŸ”„ config_compat.py       # Legacy configuration compatibility

ğŸ“ scripts/
â”œâ”€â”€ ğŸ·ï¸ version.py             # Version management system
â”œâ”€â”€ ğŸ”„ dev-workflow.py        # Development automation
â”œâ”€â”€ ğŸ¤ collaborate.py         # Collaboration helpers
â””â”€â”€ ğŸ“‹ generate_report.py     # Report generation utility

ğŸ“ docs/
â”œâ”€â”€ ğŸ¤ COLLABORATION_GUIDE.md # Detailed collaboration guide
â”œâ”€â”€ âš™ï¸ configuration.md       # Configuration reference
â”œâ”€â”€ ğŸ”¬ methodology.md         # Research methodology (updated)
â””â”€â”€ ğŸ“š experiment_design.md # Experiment configuration guide

ğŸ“ tests/
â”œâ”€â”€ ğŸ§ª test_calibration.py    # Calibration testing
â”œâ”€â”€ ğŸ§ª test_configuration.py  # Configuration system testing
â”œâ”€â”€ ğŸ§ª test_journal_manager.py # Journal management testing
â”œâ”€â”€ ğŸ§ª test_memory_system.py  # Memory system integration
â”œâ”€â”€ ğŸ§ª test_performance_tracker.py # Performance tracking testing
â””â”€â”€ ğŸ§ª test_trade_history_manager.py # Trading history testing

ğŸ“ data/
â”œâ”€â”€ ğŸ“¥ raw/                   # Raw financial data (tracked)
â””â”€â”€ ğŸ“¤ processed/             # Processed data (gitignored)

ğŸ“ example_results/           # ğŸ“‹ Example outputs for documentation
ğŸ“ results/                   # ğŸ“Š Generated results (gitignored)

ğŸ“ .github/
â”œâ”€â”€ ğŸ¤– workflows/ci.yml       # CI/CD pipeline
â”œâ”€â”€ ğŸ”„ dependabot.yml         # Automated dependency updates
â”œâ”€â”€ ğŸ“‹ PULL_REQUEST_TEMPLATE.md # PR guidelines
â””â”€â”€ ğŸ› ISSUE_TEMPLATE/         # Issue templates

ğŸ“ results/
â”œâ”€â”€ ğŸ“Š analysis/              # Statistical validation JSON/CSV
â”œâ”€â”€ ğŸ“ˆ plots/                 # Calibration, patterns, risk analysis
â”œâ”€â”€ ğŸ“‹ reports/               # Comprehensive experiment reports
â””â”€â”€ ğŸ“„ parsed/                # Processed trading decisions
```

---

## ğŸ“ˆ Trading Strategies

### ğŸ¤– LLM Strategy Configurations

| Configuration | Memory | Feelings | Dates | Purpose |
|---------------|--------|----------|-------|---------|
| **baseline** | âŒ | âŒ | âŒ | Pure LLM without context |
| **memory_only** | âœ… | âŒ | âŒ | Strategic journal learning |
| **memory_feeling** | âœ… | âœ… | âŒ | Emotional state tracking |
| **dates_memory** | âœ… | âŒ | âœ… | Temporal awareness âš ï¸ |
| **dates_full** | âœ… | âœ… | âœ… | Complete context âš ï¸ |

**âš ï¸ Research Note**: Date-enabled configurations shouldn't be used if you wan to prevent data leakage from historical knowledge contamination.

### ğŸ¯ Baseline Strategies
| Strategy | Logic | Parameters | 2015-2017 Return |
|----------|-------|------------|------------------|
| **Buy & Hold** | Passive index | - | +14.2% |
| **Momentum** | Trend following | 20-day MA | +5.1% |
| **Mean Reversion** | Buy dips | Â±2Ïƒ thresholds | +5.5% |
| **Volatility Timing** | Risk management | 20% vol threshold | +11.1% |
| **Contrarian** | Fade extremes | Inverse signals | +9.1% |
| **Random** | Statistical baseline | Equal weights | -0.03% |

---

## ğŸ“Š Statistical Validation Framework

### Bootstrap Significance Testing
```python
# Rigorous statistical comparison
bootstrap_results = bootstrap_sharpe_comparison(
    llm_returns, benchmark_returns, n_bootstrap=5000
)

print(f"p-value: {bootstrap_results['p_value_two_sided']:.4f}")
print(f"95% CI: [{bootstrap_results['ci_95_bootstrap'][0]:+.3f}, {bootstrap_results['ci_95_bootstrap'][1]:+.3f}]")
```

**Key Features:**
- âœ… 5,000 bootstrap resamples for robust significance testing
- âœ… Confidence intervals account for return distribution non-normality
- âœ… Effect sizes (Cohen's d) for practical significance
- âœ… Multiple testing corrections

### Out-of-Sample Validation
```
OUT-OF-SAMPLE VALIDATION:
  Train Period: -0.060 Sharpe (750 periods: 2015-2018)
  Test Period:  -0.060 Sharpe (250 periods: 2018-2019)
  Sharpe Decay: 0.0% reduction ğŸš¨ OVERFITTING DETECTED
  Confidence: 95% statistical validation with 5,000 bootstrap samples
```

### HOLD Decision Analysis (Dual-Criteria)
```
HOLD DECISION ANALYSIS:
Overall Success Rate: 40.4% (POOR)

Quiet Market Success (<0.2% moves): 0.6% âœ… Appropriate caution
Contextual Correctness: 100.0% âœ… Right conditions
Combined Score: 40.4% âš ï¸ Too conservative overall
```

---

## ğŸ“‹ Sample Results

### Performance Comparison
```
STRATEGY COMPARISON - dummy_model_memory_feeling
================================================================================
Strategy                 Return    Sharpe   MaxDD   Win%
buy_and_hold             30.5%     0.562   -33.9%   54.2
momentum                 25.8%     0.489   -25.1%   51.3
LLM_STRATEGY             -2.6%     -0.060  -45.2%   48.7 â—„
random_mean (n=30)       -15.4%     N/A     N/A     N/A
================================================================================
```

### Statistical Significance
```
BOOTSTRAP TEST VS INDEX:
  Strategy Sharpe: -0.060
  Index Sharpe: 0.562
  Difference: -0.622
  p-value: 0.384 (NOT SIGNIFICANT)
  95% CI: [-2.000, +0.754]
```

### HOLD Analysis
```
HOLD DECISION ANALYSIS
Overall HOLD Success Rate: 40.0% (GOOD)

Quiet Market Success (<0.2% Daily Moves): 40.0%
Contextual Decision Correctness: 100.0%
```

---

## ğŸ¨ Generated Visualizations

- **ğŸ“Š Baseline Comparisons**: Bar charts, equity curves
- **ğŸ¯ Calibration Plots**: Prediction accuracy, confidence analysis
- **ğŸ“ˆ Risk Analysis**: VaR curves, drawdown timelines, stress tests
- **ğŸ“‹ Decision Patterns**: Win rates by scenario, position duration
- **ğŸ“‰ Rolling Performance**: Sharpe evolution, volatility tracking

---

## ğŸ”¬ Methodology Details

### Experimental Design
- **Data**: Daily stock/index prices (customizable period and source)
- **LLM Models**: BERT, GPT, Claude, Gemini via OpenRouter API
- **Evaluation**: Bootstrap significance testing, out-of-sample validation
- **Backtesting**: Configurable assumptions and transaction costs

### Statistical Framework
- **Primary Metric**: Risk-adjusted returns (Sharpe ratio)
- **Significance Level**: p < 0.05 (bootstrap tests)
- **Validation**: Chronological train/test splits
- **HOLD Evaluation**: Dual-criteria assessment (quiet markets + context)

### Decision Analysis Pipeline
1. **LLM Response Parsing** â†’ Decision + Probability + Explanation + Journal
2. **Calibration Assessment** â†’ Confidence vs Reality analysis
3. **Pattern Recognition** â†’ Behavioral pattern detection
4. **HOLD Evaluation** â†’ Dual-criteria success assessment
5. **Statistical Validation** â†’ Bootstrap significance testing

---

## ğŸ“– Usage Examples

### Run Complete Experiment
```bash
# Configure in src/config.py
ACTIVE_EXPERIMENT = "memory_only"  # or "baseline", "dates_memory", etc.

# Run pipeline
python -m src.main
```

### Analyze Specific Model
```python
from src.report_generator import generate_comprehensive_report

# Generate full research report
report_path = generate_comprehensive_report("bert_memory_only")
print(f"Report saved: {report_path}")
```

### Statistical Validation
```python
from src.statistical_validation import comprehensive_statistical_validation

# Run full validation suite
validation = comprehensive_statistical_validation(parsed_df, model_tag)
print(f"LLM vs Index p-value: {validation['bootstrap_vs_index']['p_value']}")
```

---



## ğŸ”¬ Future Research Directions

### Immediate Extensions
- **Technical Indicator Baselines**: Develop new baseline strategies using MACD, Stochastic, and Bollinger Bands signals
- **Enhanced Feature Engineering**: Improve prompt engineering with market regime detection and advanced technical analysis
- **Chain of Thoughts Reasoning**: Implement structured step-by-step reasoning prompts to improve LLM decision quality and explainability
- **Ensemble Methods**: Combine multiple LLM predictions for improved decision quality
- **Data Frequency Analysis**: Extend beyond daily data to intraday trading decisions
- **Cross-Model Comparison**: BERT vs GPT vs Claude calibration differences
- **Market Regime Analysis**: Calibration stability across bull/bear cycles


### Long-Term Questions
- **AI Behavioral Training**: Can we train LLMs to avoid human cognitive biases?
- **Disposition Effect Analysis**: Implement detection of premature profit-taking and excessive loss-holding patterns
- **Prospect Theory Implementation**: Study risk-seeking in losses vs risk-averse behavior in gains
- **Survivorship Bias Testing**: Evaluate performance on delisted/failed stocks to avoid backtesting illusions
- **Hybrid Systems**: Combining LLM intuition with quantitative risk management
- **Real-Time Adaptation**: Online learning from live trading feedback
- **Multi-Asset Extension**: Beyond single-stock to portfolio optimization

---

## ğŸ“– Documentation

- **[Configuration Guide](docs/configuration.md)**: Complete setup and configuration options
- **[Research Methodology](docs/methodology.md)**: Statistical framework and experimental design
- **[Test Suite Documentation](tests/TEST_DOCUMENTATION.md)**: Comprehensive test coverage and validation details
- **[Contributing Guide](CONTRIBUTING.md)**: How to contribute to the project
- **[Experiment Design Guide](docs/experiment_design.md)**: Comprehensive experiment configuration and research methodology

## ğŸ¤ Contributing to Research

We welcome contributions from researchers, developers, and financial practitioners. See our detailed [Contributing Guide](CONTRIBUTING.md) for comprehensive information.

### Quick Start for Contributors
- **ğŸ“– Read the [Contributing Guide](CONTRIBUTING.md)** for detailed instructions
- **ğŸ”¬ Research**: Test new LLMs, develop strategies, enhance statistical methods
- **ğŸ’» Code**: Bug fixes, features, performance improvements
- **ğŸ§ª Testing**: Add test coverage, validate results
- **ğŸ“š Docs**: Improve documentation and tutorials

### Research Opportunities
- **Model Benchmarking**: Compare BERT, Claude, Gemini, and emerging LLMs
- **Strategy Development**: New baseline strategies and prompting techniques
- **Market Analysis**: Test across different markets and time periods
- **Behavioral Research**: Develop new AI bias detection methods

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **OpenRouter** for LLM API access
- **Open-source community** for financial data libraries and research tools

---

This framework provides methodological tools for systematic investigation of artificial intelligence in financial decision-making, integrating computational methods with behavioral economics and quantitative finance.
